{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliwadler/image_classification/blob/main/cat_dog_classification_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bildklassifikation - üò∫ vs. üê∂**"
      ],
      "metadata": {
        "id": "e4LR23FqytQV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jpGc-f0YM8H"
      },
      "source": [
        "## Bibliotheken importieren\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd7hDq8KXUed"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gdown\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from PIL import Image as image_p\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAnJam64UT90"
      },
      "source": [
        "## Bilder laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1fXlMeMW1YO"
      },
      "outputs": [],
      "source": [
        "# Download the dataset zip file\n",
        "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "filename = \"cats_and_dogs_filtered.zip\"\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images in train/cats:\",  len(os.listdir('cats_and_dogs_filtered/train/cats')))\n",
        "print(\"Number of images in train/dogs:\",  len(os.listdir('cats_and_dogs_filtered/train/dogs')))\n",
        "\n",
        "print(\"Number of images in validation/cats:\",  len(os.listdir('cats_and_dogs_filtered/validation/cats')))\n",
        "print(\"Number of images in validation/dogs:\",  len(os.listdir('cats_and_dogs_filtered/validation/dogs')))"
      ],
      "metadata": {
        "id": "3JIUA4JY07Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QXwEJ_TaoAe"
      },
      "source": [
        "## Daten vorbereiten\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtSQBahSXYrh"
      },
      "outputs": [],
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    # 10% of the training images will be used for validation\n",
        "    validation_split=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'cats_and_dogs_filtered/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        subset='training',\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        'cats_and_dogs_filtered/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        subset='validation',\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beispielbilder"
      ],
      "metadata": {
        "id": "Rx7JxgJCeLFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print some pictures from the train_generator\n",
        "images, labels = next(train_generator)\n",
        "fig, axes = plt.subplots(3, 4)\n",
        "axes = axes.ravel()\n",
        "for i in range(12):\n",
        "    axes[i].imshow(images[i])\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title('Label: {}'.format(labels[i]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "40RgLWyL2W8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpqTdvfyw5Sm"
      },
      "source": [
        "### *Beispiel Augementierung eines Bildes*\n",
        "\n",
        "Hier wird die ImageDataGenerator-Instanz **train_datagen** verwendet um die Argumentation eines Beispielbildes zu veranschaulichen. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXAzYB9Vt7u_"
      },
      "outputs": [],
      "source": [
        "# get all files from the train/cat directory\n",
        "fnames = [os.path.join('cats_and_dogs_filtered/train/cats', fname) for\n",
        "  fname in os.listdir('cats_and_dogs_filtered/train/cats')]\n",
        "\n",
        "#TODO\n",
        "# get one picture\n",
        "img_path = fnames[ random.randint(0,1000)]\n",
        "img = load_img(img_path, target_size=(150, 150))\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# plot the result - use subplot to display them next to each other\n",
        "fig, axs = plt.subplots(1, 4, figsize=(12, 12))\n",
        "i = 0\n",
        "for batch in train_datagen.flow(x, batch_size=1):\n",
        "    axs[i].imshow(array_to_img(batch[0]))\n",
        "    axs[i].axis('off')\n",
        "    i += 1\n",
        "    if i >= 4:\n",
        "        break\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p06t6P-6w7z"
      },
      "source": [
        "## Modell definieren\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTveRchwXfxA"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.15),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= tf.optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# shows each layer\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YACrxcXw67zx"
      },
      "source": [
        "## Modell trainieren\n",
        "\n",
        "**Da das Trainieren das Modells den heutigen Zeitraum sprengen w√ºrde werden wir das ein zuvor von mir trainiertes Modell in den weiteren Schritten verwenden**!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Y4cVxuXujX"
      },
      "outputs": [],
      "source": [
        "'''history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=len(train_generator),\n",
        "      epochs=140,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=len(validation_generator)) '''\n",
        "\n",
        "\n",
        "# load pretrained model\n",
        "gdown.download_folder('https://drive.google.com/drive/folders/1MPrC5o7rI8_EYEZ6TLOWsWes44JKk-aD?usp=sharing')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('Assets_Modell/cats_dogs_classifier_82%.h5')"
      ],
      "metadata": {
        "id": "KLivHJEC0KkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8LDxx2JIOJw"
      },
      "source": [
        "## Modell validieren"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testdaten laden"
      ],
      "metadata": {
        "id": "lCEL8p5FXxdp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syxKdIURX1yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Validation accurary  & -loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r6yzUWSfXAWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd0GfBqEAvKT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "aaFUtWqOW54L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8SO9pxLB1t0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1 Score"
      ],
      "metadata": {
        "id": "b1bGPjLzdNAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "JOMt6MjGRqLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Loss & Accuracy"
      ],
      "metadata": {
        "id": "lOfsEyaTdXuj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCyedHrFRbXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anwenden des Modells"
      ],
      "metadata": {
        "id": "mqHHOhYvpBo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SZujwhbgWF9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the image and resize to the target size\n",
        "\n",
        "#img_path = 'cats_and_dogs_filtered/validation/dogs/dog.2197.jpg'\n",
        "#img_path = 'cats_and_dogs_filtered/validation/dogs/dog.2013.jpg'\n",
        "#img_path = 'cats_and_dogs_filtered/validation/cats/cat.2019.jpg'\n",
        "img_path = 'cats_and_dogs_filtered/validation/cats/cat.2119.jpg'\n",
        "#img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "\n",
        "# Print the image\n",
        "image = image_p.open(img_path)\n",
        "width, height = image.size\n",
        "new_width = 200\n",
        "new_height = int(height * (new_width / width))\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "resized_image.show()\n",
        "\n",
        "  # Convert the image to a numpy array and normalize\n",
        "img_array = img_to_array(img)\n",
        "img_array /= 255.\n",
        "\n",
        "  # Expand the dimensions of the image array to match the model input shape\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "  # Predict the class of the image\n",
        "pred = model.predict(img_array, verbose=0)\n",
        "pred_probability = pred[0][0]\n",
        "if pred_probability > 0.5:\n",
        "    print(\"Based on my expert analysis, that appears to be a \\033[95m\\033[1m DOG\\033[0m.\")\n",
        "else:\n",
        "    print(\"Meow, that's most definitely a \\033[95m\\033[1m CAT\\033[0m!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap\n",
        "\n",
        "Eine Heatmap ist eine visuelle Darstellung von Daten, die in Form einer Farbskala dargestellt werden. \n",
        "Sie sind n√ºtzlich um bestimmte Muster und Zusammenh√§nge in den Daten zu erkennen. Zum Beispiel kann man sie nutzen, um zu sehen, welche Bereiche in einem Bild am meisten Aktivit√§t aufweisen, also f√ºr das Model am relevantesten f√ºr die Klassifizierung sind. \n"
      ],
      "metadata": {
        "id": "CMuvepcsSh9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from cv2 import hconcat, imread, applyColorMap, resize, COLORMAP_JET, waitKey, destroyAllWindows, vconcat\n",
        "from google.colab.patches import cv2_imshow "
      ],
      "metadata": {
        "id": "DHqd6EYwNcDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funktion um Heatmap zu kreieren"
      ],
      "metadata": {
        "id": "8eDIRWZJOUWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_heatmap(orig):\n",
        "\n",
        "  # define intensity of colormap and size of pictures\n",
        "  intensity=0.5\n",
        "  res= 150\n",
        "  img = load_img(orig, target_size=(150, 150))\n",
        "\n",
        "  # Convert the image to a numpy array and normalize\n",
        "  img_array = img_to_array(img)\n",
        "  img_array /= 255.\n",
        "\n",
        "  # Expand the dimensions of the image array to match the model input shape\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "  # Predict the class of the image\n",
        "  pred = model.predict(img_array, verbose=0)\n",
        "  pred_probability = pred[0][0]\n",
        "  if pred_probability > 0.5:\n",
        "    print('dog', end='; ')\n",
        "  else:\n",
        "    print('cat', end='; ')\n",
        "\n",
        "  # Magic - visualize the regions of the image that are most important for the model\n",
        "  with tf.GradientTape() as tape:\n",
        "    last_conv_layer = model.get_layer('conv2d_3')\n",
        "    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "    model_out, last_conv_layer = iterate(img_array)\n",
        "    class_out = model_out[:, np.argmax(model_out[0])]\n",
        "    grads = tape.gradient(class_out, last_conv_layer)\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "      \n",
        "  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  heatmap /= np.max(heatmap)\n",
        "  heatmap = heatmap.reshape((15, 15))\n",
        "\n",
        "  img = imread(orig)\n",
        "\n",
        "  heatmap = resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = applyColorMap(np.uint8(255*heatmap), COLORMAP_JET)\n",
        "  # place Heatmap above picture\n",
        "  img = heatmap * intensity + img\n",
        "  return resize(img, (res, res))"
      ],
      "metadata": {
        "id": "TFIGK1rfVJQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test einiger Bilder\n"
      ],
      "metadata": {
        "id": "bvfjU10RSSBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define images\n",
        "images = [\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2009.jpg',\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2102.jpg',\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2103.jpg',\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2104.jpg',\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2105.jpg',\n",
        "    'cats_and_dogs_filtered/validation/cats/cat.2001.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2001.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2102.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2103.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2104.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2167.jpg',\n",
        "    'cats_and_dogs_filtered/validation/dogs/dog.2197.jpg'\n",
        "]\n",
        "\n",
        "heatmap_images = []\n",
        "\n",
        "for image in images:\n",
        "    heatmap_images.append(create_heatmap(image))\n",
        "\n",
        "# Print results\n",
        "result1 = hconcat(heatmap_images[:6])\n",
        "result2 = hconcat(heatmap_images[6:])\n",
        "result = vconcat([result1, result2])\n",
        "\n",
        "cv2_imshow(result)\n",
        "waitKey(0)\n",
        "destroyAllWindows()"
      ],
      "metadata": {
        "id": "D-Y3NrFi-f5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}